# Prism
Prism is Multi-modal LLM. You can Customize with Prism Training Script.

## Models
- (Preview) **Prism 0.2:** [Published](https://huggingface.co/DiamondGotCat/Prism-0.2)
- (Preview) **Prism 0.3:** Building... (Plan)
- (Preview) **Prism 0.4:** Building... (Plan)
- (Preview) **Prism 0.5:** Building... (Plan)
- (Preview) **Prism 0.6:** Building... (Plan)
- (Preview) **Prism 0.7:** Building... (Plan)
- (Preview) **Prism 0.8:** Building... (Plan)
- (Preview) **Prism 0.9:** Building... (Plan)
- (Stable) **Prism 1.0:** Building... (Plan)

## How
I used Transformers Library.

### Based Models
- **Prism 0.2:** Text `Qwen/Qwen2.5-0.5B`,  Vision `openai/clip-vit-base-patch32`, Audio `facebook/wav2vec2-base-960h`

### Based Extra Datasets
- **Prism 0.2:** Text `DiamondGotCat/Azuki-2n`
    - (No Extra Dataset for Vision/Audio, so Not Good for Multi-modal Model)
